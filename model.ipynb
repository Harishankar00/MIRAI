{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm  # for Swin Transformer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "print(\"Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammoDataset(Dataset):\n",
    "    def __init__(self, root_dir, class_names=['Benign', 'Malignant', 'Normal', 'Suspicious'], \n",
    "                 transforms=None, mask_transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str or Path): Root directory containing 'Preprocessed_Dataset' and 'Masks'\n",
    "            class_names (list): Classes to consider (subfolder names)\n",
    "            transforms: Transformations applied to images\n",
    "            mask_transforms: Transformations applied to masks\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.class_names = class_names\n",
    "        self.transforms = transforms\n",
    "        self.mask_transforms = mask_transforms\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Map from class name to numeric label for classification\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "        \n",
    "        # Gather all image and mask paths with labels\n",
    "        for cls in class_names:\n",
    "            image_base = self.root_dir / 'Preprocessed_Dataset' / cls\n",
    "            mask_base = self.root_dir / 'Masks' / cls\n",
    "            \n",
    "            # For each source dataset folder\n",
    "            for source_dir in image_base.iterdir():\n",
    "                if source_dir.is_dir():\n",
    "                    for img_file in source_dir.glob('*'):\n",
    "                        img_path = img_file\n",
    "                        mask_path = mask_base / source_dir.name / img_file.name\n",
    "                        if mask_path.exists():\n",
    "                            self.image_paths.append(img_path)\n",
    "                            self.mask_paths.append(mask_path)\n",
    "                            self.labels.append(self.class_to_idx[cls])\n",
    "                        else:\n",
    "                            print(f\"Mask not found for {img_path}, skipping.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image and mask as grayscale\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        if self.mask_transforms:\n",
    "            mask = self.mask_transforms(mask)\n",
    "        \n",
    "        return image, mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86732fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip\n",
    "\n",
    "# Grayscale normalization values (mean and std for single channel)\n",
    "mean = [0.5]\n",
    "std = [0.5]\n",
    "\n",
    "# Training image transformations\n",
    "train_transforms = Compose([\n",
    "    Resize((224, 224)),              # Resize to 224x224 to match Swin input\n",
    "    RandomHorizontalFlip(),          # Data augmentation: horizontal flip\n",
    "    ToTensor(),                     # Convert to tensor\n",
    "    Normalize(mean=mean, std=std),  # Normalize image\n",
    "])\n",
    "\n",
    "# Mask transforms (no normalization, just resize and tensor)\n",
    "mask_transforms = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset root directory\n",
    "dataset_root = './Dataset'  # Adjust if different\n",
    "\n",
    "# Create dataset instances\n",
    "full_dataset = MammoDataset(root_dir=dataset_root, \n",
    "                            transforms=train_transforms, \n",
    "                            mask_transforms=mask_transforms)\n",
    "\n",
    "# Split dataset into train and validation sets (e.g., 80/20 split, stratified)\n",
    "from sklearn.model_selection import train_test_split\n",
    "indices = list(range(len(full_dataset)))\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42, stratify=full_dataset.labels)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "# DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)  # Using batch size 4 for RTX 3050 memory\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "# Sanity check: fetch a batch and print shapes\n",
    "images, masks, labels = next(iter(train_loader))\n",
    "print(f'Image batch shape: {images.shape}')   # Expected: [4, 1, 224, 224]\n",
    "print(f'Mask batch shape: {masks.shape}')    # Expected: [4, 1, 224, 224]\n",
    "print(f'Label batch shape: {labels.shape}')  # Expected: [4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a618cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a smaller Swin Transformer variant to fit RTX 3050 memory\n",
    "model_name = 'swin_tiny_patch4_window7_224'   # Smaller variant\n",
    "\n",
    "# Create model with pretrained weights, 4-class output\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=4)\n",
    "\n",
    "# Modify input conv layer to accept 1 channel instead of 3 (RGB)\n",
    "old_conv = model.patch_embed.proj\n",
    "new_conv = torch.nn.Conv2d(1, old_conv.out_channels, kernel_size=old_conv.kernel_size,\n",
    "                           stride=old_conv.stride, padding=old_conv.padding, bias=old_conv.bias is not None)\n",
    "\n",
    "# Initialize new conv weights by averaging pretrained weights across RGB channels\n",
    "new_conv.weight.data = old_conv.weight.data.mean(dim=1, keepdim=True)\n",
    "if old_conv.bias is not None:\n",
    "    new_conv.bias.data = old_conv.bias.data\n",
    "\n",
    "model.patch_embed.proj = new_conv\n",
    "\n",
    "# Move model to GPU or CPU\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb317f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: CrossEntropy for multi-class classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: AdamW popular for transformers\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler: cosine annealing for smooth decrease\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Training loop\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress = tqdm(dataloader, desc=\"Training\")\n",
    "\n",
    "    for images, masks, labels in progress:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        progress.set_postfix(loss=running_loss/total, accuracy=correct/total)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_and_save(history, metric, filename):\n",
    "    plt.figure()\n",
    "    plt.plot(history['train_'+metric], label='Train '+metric)\n",
    "    plt.plot(history['val_'+metric], label='Val '+metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'Train vs Val {metric}')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device,\n",
    "                num_epochs=20, patience=5, checkpoint_dir='./checkpoints'):\n",
    "    \n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}, Val   Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Append history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Save checkpoint for every epoch\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "        \n",
    "        # Early stopping treatment\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"New best model saved: {best_model_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1} with no improvement for {patience} epochs\")\n",
    "                break\n",
    "\n",
    "    # Save loss and accuracy plots\n",
    "    plot_and_save(history, 'loss', os.path.join(checkpoint_dir, 'loss_plot.png'))\n",
    "    plot_and_save(history, 'acc', os.path.join(checkpoint_dir, 'accuracy_plot.png'))\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks, labels in tqdm(dataloader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds,\n",
    "                                target_names=['Benign', 'Malignant', 'Normal', 'Suspicious']))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d',\n",
    "                xticklabels=['Benign', 'Malignant', 'Normal', 'Suspicious'],\n",
    "                yticklabels=['Benign', 'Malignant', 'Normal', 'Suspicious'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('test_confusion_matrix.png')\n",
    "    plt.show()\n",
    "\n",
    "# Usage example:\n",
    "# Load best model weights\n",
    "# model.load_state_dict(torch.load('./checkpoints/best_model.pth'))\n",
    "# model.to(device)\n",
    "\n",
    "# Prepare test_loader (similar to val_loader, from test subset)\n",
    "# evaluate_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs and patience for early stopping\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "\n",
    "# Start training, checkpoints and history plots will be saved in './checkpoints'\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device,\n",
    "                      num_epochs=num_epochs, patience=patience, checkpoint_dir='./checkpoints')\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b503d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_dataset</th>\n",
       "      <th>laterality</th>\n",
       "      <th>view</th>\n",
       "      <th>preprocessed_image_path</th>\n",
       "      <th>classification</th>\n",
       "      <th>density</th>\n",
       "      <th>BIRADS</th>\n",
       "      <th>abnormality</th>\n",
       "      <th>molecular_subtype</th>\n",
       "      <th>raw_image_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>ROI_path</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>radius</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>source_subjectID</th>\n",
       "      <th>original_source_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inbreast</td>\n",
       "      <td>R</td>\n",
       "      <td>CC</td>\n",
       "      <td>Preprocessed_Dataset/inbreast/inbreast_0.jpg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original_Dataset/inbreast/inbreast_0.jpg</td>\n",
       "      <td>Masks/inbreast/inbreast_0.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22678622</td>\n",
       "      <td>INbreast/AllDICOMs/22678622_61b13c59bcba149e_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inbreast</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>Preprocessed_Dataset/inbreast/inbreast_1.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>D</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original_Dataset/inbreast/inbreast_1.jpg</td>\n",
       "      <td>Masks/inbreast/inbreast_1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22678646</td>\n",
       "      <td>INbreast/AllDICOMs/22678646_61b13c59bcba149e_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inbreast</td>\n",
       "      <td>R</td>\n",
       "      <td>MLO</td>\n",
       "      <td>Preprocessed_Dataset/inbreast/inbreast_2.jpg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original_Dataset/inbreast/inbreast_2.jpg</td>\n",
       "      <td>Masks/inbreast/inbreast_2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22678670</td>\n",
       "      <td>INbreast/AllDICOMs/22678670_61b13c59bcba149e_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inbreast</td>\n",
       "      <td>L</td>\n",
       "      <td>MLO</td>\n",
       "      <td>Preprocessed_Dataset/inbreast/inbreast_3.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>D</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original_Dataset/inbreast/inbreast_3.jpg</td>\n",
       "      <td>Masks/inbreast/inbreast_3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22678694</td>\n",
       "      <td>INbreast/AllDICOMs/22678694_61b13c59bcba149e_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inbreast</td>\n",
       "      <td>R</td>\n",
       "      <td>CC</td>\n",
       "      <td>Preprocessed_Dataset/inbreast/inbreast_4.jpg</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>B</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original_Dataset/inbreast/inbreast_4.jpg</td>\n",
       "      <td>Masks/inbreast/inbreast_4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22614074</td>\n",
       "      <td>INbreast/AllDICOMs/22614074_6bd24a0a42c19ce1_M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_dataset laterality view  \\\n",
       "0       inbreast          R   CC   \n",
       "1       inbreast          L   CC   \n",
       "2       inbreast          R  MLO   \n",
       "3       inbreast          L  MLO   \n",
       "4       inbreast          R   CC   \n",
       "\n",
       "                        preprocessed_image_path classification density  \\\n",
       "0  Preprocessed_Dataset/inbreast/inbreast_0.jpg         Normal       D   \n",
       "1  Preprocessed_Dataset/inbreast/inbreast_1.jpg         Benign       D   \n",
       "2  Preprocessed_Dataset/inbreast/inbreast_2.jpg         Normal       D   \n",
       "3  Preprocessed_Dataset/inbreast/inbreast_3.jpg         Benign       D   \n",
       "4  Preprocessed_Dataset/inbreast/inbreast_4.jpg      Malignant       B   \n",
       "\n",
       "   BIRADS abnormality  molecular_subtype  \\\n",
       "0     1.0         NaN                NaN   \n",
       "1     3.0         NaN                NaN   \n",
       "2     1.0         NaN                NaN   \n",
       "3     3.0         NaN                NaN   \n",
       "4     5.0         NaN                NaN   \n",
       "\n",
       "                             raw_image_path                      mask_path  \\\n",
       "0  Original_Dataset/inbreast/inbreast_0.jpg  Masks/inbreast/inbreast_0.jpg   \n",
       "1  Original_Dataset/inbreast/inbreast_1.jpg  Masks/inbreast/inbreast_1.jpg   \n",
       "2  Original_Dataset/inbreast/inbreast_2.jpg  Masks/inbreast/inbreast_2.jpg   \n",
       "3  Original_Dataset/inbreast/inbreast_3.jpg  Masks/inbreast/inbreast_3.jpg   \n",
       "4  Original_Dataset/inbreast/inbreast_4.jpg  Masks/inbreast/inbreast_4.jpg   \n",
       "\n",
       "  ROI_path   x   y  radius  subject_age source_subjectID  \\\n",
       "0      NaN NaN NaN     NaN          NaN         22678622   \n",
       "1      NaN NaN NaN     NaN          NaN         22678646   \n",
       "2      NaN NaN NaN     NaN          NaN         22678670   \n",
       "3      NaN NaN NaN     NaN          NaN         22678694   \n",
       "4      NaN NaN NaN     NaN          NaN         22614074   \n",
       "\n",
       "                                original_source_path  \n",
       "0  INbreast/AllDICOMs/22678622_61b13c59bcba149e_M...  \n",
       "1  INbreast/AllDICOMs/22678646_61b13c59bcba149e_M...  \n",
       "2  INbreast/AllDICOMs/22678670_61b13c59bcba149e_M...  \n",
       "3  INbreast/AllDICOMs/22678694_61b13c59bcba149e_M...  \n",
       "4  INbreast/AllDICOMs/22614074_6bd24a0a42c19ce1_M...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Subset/mammo-bench_BIRADS.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f86d21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_dataset', 'laterality', 'view', 'preprocessed_image_path',\n",
      "       'classification', 'density', 'BIRADS', 'abnormality',\n",
      "       'molecular_subtype', 'raw_image_path', 'mask_path', 'ROI_path', 'x',\n",
      "       'y', 'radius', 'subject_age', 'source_subjectID',\n",
      "       'original_source_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(birads_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36984d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated subset catalog with BIRADS scores where filenames matched!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to your files\n",
    "subset_path = 'Subset/subset_catalog.xlsx'\n",
    "birads_csv_path = 'Subset/mammo-bench_BIRADS.csv'\n",
    "\n",
    "# Load subset catalog Excel and birads CSV\n",
    "subset_df = pd.read_excel(subset_path)\n",
    "birads_df = pd.read_csv(birads_csv_path)\n",
    "\n",
    "# Extract only filename from Preprocessed_image_path in birads\n",
    "birads_df['birads_image_name'] = birads_df['preprocessed_image_path'].apply(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "# Create lookup dictionary from birads filenames to BIRADS scores\n",
    "birads_lookup = dict(zip(birads_df['birads_image_name'], birads_df['BIRADS']))\n",
    "\n",
    "# Map BIRADS score to subset based on matching image names\n",
    "subset_df['BIRADS'] = subset_df['image_name'].map(birads_lookup)\n",
    "\n",
    "# Save back to the same Excel with BIRADS column added\n",
    "subset_df.to_excel(subset_path, index=False)\n",
    "\n",
    "print(\"Updated subset catalog with BIRADS scores where filenames matched!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c1a5ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'label', 'relative_image_path', 'relative_mask_path',\n",
       "       'BIRADS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Subset/subset_catalog.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "feda7231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71844 entries, 0 to 71843\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   source_dataset           71844 non-null  object \n",
      " 1   laterality               71844 non-null  object \n",
      " 2   view                     71824 non-null  object \n",
      " 3   preprocessed_image_path  71844 non-null  object \n",
      " 4   classification           43425 non-null  object \n",
      " 5   density                  41319 non-null  object \n",
      " 6   BIRADS                   30383 non-null  float64\n",
      " 7   abnormality              5712 non-null   object \n",
      " 8   molecular_subtype        2956 non-null   object \n",
      " 9   raw_image_path           71844 non-null  object \n",
      " 10  mask_path                71844 non-null  object \n",
      " 11  ROI_path                 3099 non-null   object \n",
      " 12  x                        308 non-null    float64\n",
      " 13  y                        308 non-null    float64\n",
      " 14  radius                   306 non-null    float64\n",
      " 15  subject_age              70875 non-null  float64\n",
      " 16  source_subjectID         71844 non-null  object \n",
      " 17  original_source_path     71844 non-null  object \n",
      "dtypes: float64(5), object(13)\n",
      "memory usage: 9.9+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6363/1353692452.py:1: DtypeWarning: Columns (7,8,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Subset/mammo-bench.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Subset/mammo-bench.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea9effd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null BIRADS values replaced with NaN and saved in the subset catalog.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>relative_image_path</th>\n",
       "      <th>relative_mask_path</th>\n",
       "      <th>BIRADS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdd-cesm_1.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_1.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdd-cesm_1000.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_1000.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdd-cesm_103.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_103.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdd-cesm_104.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_104.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdd-cesm_105.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_105.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cdd-cesm_106.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_106.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cdd-cesm_111.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_111.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cdd-cesm_112.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_112.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cdd-cesm_113.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_113.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cdd-cesm_114.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_114.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cdd-cesm_115.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_115.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cdd-cesm_116.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_116.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cdd-cesm_117.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_117.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cdd-cesm_120.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_120.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cdd-cesm_121.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_121.jpg</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cdd-cesm_132.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_132.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cdd-cesm_133.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_133.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cdd-cesm_136.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_136.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cdd-cesm_137.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_137.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cdd-cesm_139.jpg</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...</td>\n",
       "      <td>Subset/Masks/Benign/cdd-cesm/cdd-cesm_139.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name   label  \\\n",
       "0      cdd-cesm_1.jpg  Benign   \n",
       "1   cdd-cesm_1000.jpg  Benign   \n",
       "2    cdd-cesm_103.jpg  Benign   \n",
       "3    cdd-cesm_104.jpg  Benign   \n",
       "4    cdd-cesm_105.jpg  Benign   \n",
       "5    cdd-cesm_106.jpg  Benign   \n",
       "6    cdd-cesm_111.jpg  Benign   \n",
       "7    cdd-cesm_112.jpg  Benign   \n",
       "8    cdd-cesm_113.jpg  Benign   \n",
       "9    cdd-cesm_114.jpg  Benign   \n",
       "10   cdd-cesm_115.jpg  Benign   \n",
       "11   cdd-cesm_116.jpg  Benign   \n",
       "12   cdd-cesm_117.jpg  Benign   \n",
       "13   cdd-cesm_120.jpg  Benign   \n",
       "14   cdd-cesm_121.jpg  Benign   \n",
       "15   cdd-cesm_132.jpg  Benign   \n",
       "16   cdd-cesm_133.jpg  Benign   \n",
       "17   cdd-cesm_136.jpg  Benign   \n",
       "18   cdd-cesm_137.jpg  Benign   \n",
       "19   cdd-cesm_139.jpg  Benign   \n",
       "\n",
       "                                  relative_image_path  \\\n",
       "0   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "1   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "2   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "3   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "4   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "5   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "6   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "7   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "8   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "9   Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "10  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "11  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "12  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "13  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "14  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "15  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "16  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "17  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "18  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "19  Subset/Preprocessed_Dataset/Benign/cdd-cesm/cd...   \n",
       "\n",
       "                                relative_mask_path  BIRADS  \n",
       "0      Subset/Masks/Benign/cdd-cesm/cdd-cesm_1.jpg     3.0  \n",
       "1   Subset/Masks/Benign/cdd-cesm/cdd-cesm_1000.jpg     1.0  \n",
       "2    Subset/Masks/Benign/cdd-cesm/cdd-cesm_103.jpg     3.0  \n",
       "3    Subset/Masks/Benign/cdd-cesm/cdd-cesm_104.jpg     3.0  \n",
       "4    Subset/Masks/Benign/cdd-cesm/cdd-cesm_105.jpg     2.0  \n",
       "5    Subset/Masks/Benign/cdd-cesm/cdd-cesm_106.jpg     2.0  \n",
       "6    Subset/Masks/Benign/cdd-cesm/cdd-cesm_111.jpg     2.0  \n",
       "7    Subset/Masks/Benign/cdd-cesm/cdd-cesm_112.jpg     2.0  \n",
       "8    Subset/Masks/Benign/cdd-cesm/cdd-cesm_113.jpg     2.0  \n",
       "9    Subset/Masks/Benign/cdd-cesm/cdd-cesm_114.jpg     3.0  \n",
       "10   Subset/Masks/Benign/cdd-cesm/cdd-cesm_115.jpg     3.0  \n",
       "11   Subset/Masks/Benign/cdd-cesm/cdd-cesm_116.jpg     NaN  \n",
       "12   Subset/Masks/Benign/cdd-cesm/cdd-cesm_117.jpg     NaN  \n",
       "13   Subset/Masks/Benign/cdd-cesm/cdd-cesm_120.jpg     1.0  \n",
       "14   Subset/Masks/Benign/cdd-cesm/cdd-cesm_121.jpg     4.0  \n",
       "15   Subset/Masks/Benign/cdd-cesm/cdd-cesm_132.jpg     1.0  \n",
       "16   Subset/Masks/Benign/cdd-cesm/cdd-cesm_133.jpg     1.0  \n",
       "17   Subset/Masks/Benign/cdd-cesm/cdd-cesm_136.jpg     1.0  \n",
       "18   Subset/Masks/Benign/cdd-cesm/cdd-cesm_137.jpg     1.0  \n",
       "19   Subset/Masks/Benign/cdd-cesm/cdd-cesm_139.jpg     2.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "subset_path = 'Subset/subset_catalog.xlsx'\n",
    "\n",
    "# Load the subset catalog\n",
    "df = pd.read_excel(subset_path)\n",
    "# Replace null values in BIRADS column with np.nan\n",
    "df['BIRADS'] = df['BIRADS'].apply(lambda x: np.nan if pd.isnull(x) else x)\n",
    "\n",
    "# Save back to the same Excel file\n",
    "df.to_excel(subset_path, index=False)\n",
    "\n",
    "print(\"Null BIRADS values replaced with NaN and saved in the subset catalog.\")\n",
    "df.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
